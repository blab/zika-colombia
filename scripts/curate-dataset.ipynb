{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Dataset curation: making the zika-colombia fasta files for main build and supplemental analyses\n",
    "  \n",
    "This notebook contains code needed to go from a raw download of all Zika genomes in `nextstrain/fauna` to the input fasta file for the zika-colombia specific analyses (which are custom `nextstrain/augur` builds). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing that I am going to do is curate the dataset for the primary analysis. Curations steps that I would like to perform include:\n",
    "\n",
    "1. Removing sequences from any geographic areas that I do not want included in the analysis (e.g. Singapore)\n",
    "\n",
    "2. Removing any sequences that were up on GenBank, but were not actually published on, and for which we didn't receive the author's permission to include in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write any functions that I want to have for this work.\n",
    "\n",
    "## replace n's with gaps, and count n's in sequences (alignment checks)\n",
    "def count_n(sequence):\n",
    "    \"counts numbers of N's in a sequence to perform QC and see how many non-informative sites exist\"\n",
    "    counter = 0\n",
    "    for base in sequence:\n",
    "        if base == 'n':\n",
    "            counter +=1\n",
    "    return counter\n",
    "\n",
    "def sample_fasta_dict_without_replacement(dictionary,n_samples_to_draw):\n",
    "    \"\"\"randomly samples a Seq IO dictionary without replacement.\"\"\"\n",
    "    samples = random.sample(dictionary.items(), k=n_samples_to_draw)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 694 sequences downloaded from Fauna.\n",
      "Genomes from the following regions will be excluded: southeast_asia, japan_korea, china, and europe.\n",
      "There are 504 sequences meet the geographic criteria.\n"
     ]
    }
   ],
   "source": [
    "# Paths to files, keeping relational so that paths should work if someone downloads the repo as is.\n",
    "fauna_seqs_dict = SeqIO.to_dict(SeqIO.parse('../data/zika-fauna-2018-09-06.fasta', 'fasta'))\n",
    "print('There are {} sequences downloaded from Fauna.'.format(len(fauna_seqs_dict)))\n",
    "\n",
    "#Geographic pruning\n",
    "regions_to_exclude = ['southeast_asia', 'japan_korea', 'china', 'europe', 'africa']\n",
    "print('Genomes from the following regions will be excluded: {0}, {1}, {2}, and {3}.'.format(regions_to_exclude[0],regions_to_exclude[1],regions_to_exclude[2],regions_to_exclude[3]))\n",
    "\n",
    "geoPruned_seqs_dict = {fauna_seqs_dict[key].description:fauna_seqs_dict[key].seq for key in fauna_seqs_dict.keys() if key.split('|')[4] not in regions_to_exclude}\n",
    "print('There are {} sequences meet the geographic criteria.'.format(len(geoPruned_seqs_dict)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at this point, print out all the genomes are that are left, and ensure that permissions are available.\n",
    "accessions_to_check = [key for key in geoPruned_seqs_dict.keys()]\n",
    "\n",
    "strain_names = [accession.split('|')[0] for accession in accessions_to_check]\n",
    "ncbi_id = [accession.split('|')[2] for accession in accessions_to_check]\n",
    "lead_author =  [accession.split('|')[10].replace('et al','') for accession in accessions_to_check]\n",
    "\n",
    "\n",
    "accessions_df = pd.DataFrame(np.column_stack([strain_names, ncbi_id, lead_author]), columns= ['strain_name', 'accession_number','lead_author'])\n",
    "accessions_df.to_csv('../data/all_included_accessions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 431 genomes that we can include in published analyses.\n"
     ]
    }
   ],
   "source": [
    "# read in the dataframe that has the permissions information,\n",
    "# then parse that to select out all strains that can be included in a publishable analysis\n",
    "# these are the strains that should be used, and form the fauna subset we want.\n",
    "\n",
    "genome_permissions = pd.read_csv('../data/genome-permissions-2018-09-06.txt', delimiter ='\\t')\n",
    "\n",
    "publishable_strains = []\n",
    "for i in range(len(genome_permissions)):\n",
    "    record = genome_permissions.iloc[i]\n",
    "    if record['permission_to_use'] != 'permission_not_received' and record['preliminarily_include'] == 'yes':\n",
    "        publishable_strains.append(record['strain_name'])\n",
    "\n",
    "print(\"There are {} genomes that we can include in published analyses.\".format(len(publishable_strains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the strains in the publishable_strains list, pull out the full fauna headers (and sequences)\n",
    "# for each strain that can be published on.\n",
    "# then make a new fauna-formatted fasta file that can be read in to Augur for analysis.\n",
    "\n",
    "publishable_seqs_dict = {}\n",
    "for strain in publishable_strains:\n",
    "    for key in geoPruned_seqs_dict.keys():\n",
    "        if key.startswith(strain):\n",
    "            publishable_seqs_dict[key] = geoPruned_seqs_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write sequences to file\n",
    "with open('../data/publishable-zika-fauna-2018-09-06.fasta','w') as file:\n",
    "    for key in publishable_seqs_dict.keys():\n",
    "        file.write(str('>' + key + '\\n' + publishable_seqs_dict[key] + '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I want to check the quality of the sequences that I will use. Specifically, I want to know what proportion of the genome we have informative sequence calls for each sample. The following code blocks do things like count numbers of N's in a sequence, and separate out high quality sequences from low/medium quality sequences given different thresholds for the numbers of N's that are acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = SeqIO.to_dict(SeqIO.parse('../data/publishable-zika-fauna-2018-09-06.fasta', 'fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_counts_dict = {}\n",
    "for key in sequences.keys():\n",
    "    n_count = count_n(sequences[key].seq)\n",
    "    n_counts_dict[key] = n_count\n",
    "\n",
    "gaps_not_n_seqs = {}\n",
    "for key in sequences.keys():\n",
    "    n_seq = str(sequences[key].seq)\n",
    "    gap_seq = n_seq.replace('n','-')\n",
    "    gaps_not_n_seqs[key] = gap_seq\n",
    "    \n",
    "high_qual_seqs = {}\n",
    "for key in n_counts_dict.keys():\n",
    "    if key.split('|')[5] == 'colombia':\n",
    "        high_qual_seqs[key] = sequences[key].seq\n",
    "    else:\n",
    "        if float(n_counts_dict[key])/10769 < 0.2:\n",
    "            high_qual_seqs[key] = sequences[key].seq\n",
    "            \n",
    "medium_qual_seqs = {}\n",
    "for key in n_counts_dict.keys():\n",
    "    if key.split('|')[5] == 'colombia':\n",
    "        medium_qual_seqs[key] = sequences[key].seq\n",
    "    else:\n",
    "        if float(n_counts_dict[key])/10769 < 0.5:\n",
    "            medium_qual_seqs[key] = sequences[key].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/publishable-zika-fauna-2018-09-06-high-quality.fasta','w') as file:\n",
    "    for key in high_qual_seqs.keys():\n",
    "        file.write(str('>' + key + '\\n' + high_qual_seqs[key] + '\\n'))\n",
    "        \n",
    "with open('../data/publishable-zika-fauna-2018-09-06-medium-quality.fasta','w') as file:\n",
    "    for key in medium_qual_seqs.keys():\n",
    "        file.write(str('>' + key + '\\n' + medium_qual_seqs[key] + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/publishable-zika-fauna-2018-09-06-gapped.fasta','w') as file:\n",
    "    for key in gaps_not_n_seqs.keys():\n",
    "        file.write(str('>' + key + '\\n' + gaps_not_n_seqs[key] + '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make input data files for rarefaction curve supplemental analysis\n",
    "\n",
    "Next up, I want to make a little additional dataset for a supplemental analysis I'm doing, making rarefaction curves to investigate how many introductions one observes given the numbers of sequences sampled. I'm going to do this analysis for sequences from Colombia and sequences from Mexico, and it involves subsampling them down as well. \n",
    "\n",
    "In addition to this, I will need to make a \"background sequences\" file. This fasta will contain all of the sequences from the Americas that are used in the main analysis build EXCEPT for the country for which the subsampling is occurring (e.g. background file for Mexican subsampling analysis will contain all other American sequences in the main build, including all Colombian, but won't have any Mexican seuquences). Later on the in the build subsampled fastas will be concatenated with background sequences fasta in order to make Augur build input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_main_build_sequences = SeqIO.to_dict(SeqIO.parse('../data/publishable-zika-fauna-2018-10-15.fasta', 'fasta'))\n",
    "\n",
    "background_seqs_no_mexico = {all_main_build_sequences[key].description:all_main_build_sequences[key].seq for key in all_main_build_sequences.keys() if key.split('|')[5] != 'mexico'}\n",
    "\n",
    "background_seqs_no_colombia = {all_main_build_sequences[key].description:all_main_build_sequences[key].seq for key in all_main_build_sequences.keys() if key.split('|')[5]!= 'colombia'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../supplemental-analysis/rarefaction-curves/mexico/data/background_seqs_no_mexico.fasta\",\"w\") as file:\n",
    "    for key in background_seqs_no_mexico.keys():\n",
    "        file.write(str(\">\" + key + \"\\n\" + background_seqs_no_mexico[key] + \"\\n\" ))\n",
    "        \n",
    "with open(\"../supplemental-analysis/rarefaction-curves/colombia/data/background_seqs_no_colombia.fasta\",\"w\") as file:\n",
    "    for key in background_seqs_no_colombia.keys():\n",
    "        file.write(str(\">\"+ key + \"\\n\" + background_seqs_no_colombia[key] + \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 745 sequences downloaded from Fauna in the rarefaction import.\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "rarefaction_seqs_dict = SeqIO.to_dict(SeqIO.parse('/Users/alliblk/Desktop/gitrepos/fauna/data/zika.fasta', 'fasta'))\n",
    "print ('There are {} sequences downloaded from Fauna in the rarefaction import.'.format(len(rarefaction_seqs_dict)))\n",
    "\n",
    "#mexico_seqs_dict = {key:rarefaction_seqs_dict[key] for key in rarefaction_seqs_dict.keys if key.split('|')[5] == 'mexico')}\n",
    "mexico_seqs_dict = {}\n",
    "for key in rarefaction_seqs_dict.keys():\n",
    "    if key.split('|')[5] == 'mexico':\n",
    "        mexico_seqs_dict[key] = rarefaction_seqs_dict[key]\n",
    "    \n",
    "#notably not all of these sequences can be published on, so the following author's sequences should be dropped from the analysis\n",
    "drop_authors = ['Sevilla-Reyes','Balaraman','Izquierdo', 'Valdespino-Vazquez']\n",
    "\n",
    "mexican_seqs_for_use = {key:mexico_seqs_dict[key] for key in mexico_seqs_dict.keys() if key.split('|')[10] not in drop_authors}\n",
    "\n",
    "#I also don't want to include sequences that are 50% N, so checking quality. \n",
    "# I'm going to say that the sequences need to be high quality: they need to have at least 80% informative bases.\n",
    "samples_to_exclude_due_to_quality = []\n",
    "for key in mexican_seqs_for_use.keys():\n",
    "    n_count = count_n(mexican_seqs_for_use[key])\n",
    "    if n_count > (10769*0.2):\n",
    "        samples_to_exclude_due_to_quality.append(key)\n",
    "        \n",
    "high_qual_mexican_seqs_for_use = {key:mexican_seqs_for_use[key] for key in mexican_seqs_for_use.keys() if key not in samples_to_exclude_due_to_quality}\n",
    "print(len(high_qual_mexican_seqs_for_use))\n",
    "\n",
    "#Okay, high_qual_mexican_seqs is the set that should be used/subsampled for rarefaction analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm subsampling down both my Colombian and my Mexican sequence dictionaries to make the input datasets for the rarefaction curve analysis, which looks at how many introductions into a country (either Mexico or Colombia) are observed given x numbers of sequences sampled from that country. The idea is to see when this relationship asymptotes, i.e. how many sequences do you need to observe most of the introductions to a country that occurred.\n",
    "\n",
    "To get the data sets for this analysis, I need to subsample down one countries sequences, and re-run the augur pipelines with the rest of the build the same, and just look at how introductions to that country changed given numbers of sequences from that country obtained. I'll do this both for Colombia and for Mexico, but separately (i.e. any subsampled Mexican sequences will be run with all Colombian sequences and vice versa).\n",
    "\n",
    "The subsampling scheme is as follows. Try 1 sequence, 2 sequences, 3 sequences ... all the sequences, and look at numbers of introductions observed. For each subsample amount (e.g. 4 sequences) there will be 5 trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "subsampling  1  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  2  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  3  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  4  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  5  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  6  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  7  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  8  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  9  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  10  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  11  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  12  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  13  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  14  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  15  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  16  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  17  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  18  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  19  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  20  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  21  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  22  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  23  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  24  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  25  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  26  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  27  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  28  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  29  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  30  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  31  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  32  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  33  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  34  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  35  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  36  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  37  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  38  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  39  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  40  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  41  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  42  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  43  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  44  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  45  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  46  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  47  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  48  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  49  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n",
      "\n",
      "subsampling  50  genomes.\n",
      "\n",
      "working on trial number:  1\n",
      "working on trial number:  2\n",
      "working on trial number:  3\n",
      "working on trial number:  4\n",
      "working on trial number:  5\n"
     ]
    }
   ],
   "source": [
    "random.seed(123456) #setting a seed so that sampling process is reproducible\n",
    "n_trials_per_subsampling = 5\n",
    "#okay now I want to randomly sample mexican sequences, where number of trials increments by 1 until the whole dataset is grabbed\n",
    "#e.g. \n",
    "for i in range(1,len(high_qual_mexican_seqs_for_use)): #start at 1 seq, not zero, but doesn't need to do 51 because that would be no sampling.\n",
    "    print(\"\\nsubsampling \", i, \" genomes.\\n\")\n",
    "    os.mkdir(\"../supplemental-analysis/rarefaction-curves/mexico/mexico_{}_seqs\".format(i))#make a directory for each subsample number that will hold the 5 trial data.\n",
    "    for k in range(1,n_trials_per_subsampling+1): #doing this just for readibility, so that trial number is 1 through 5, rather than 0 through 4\n",
    "        print(\"working on trial number: \", k)\n",
    "        subsample = sample_fasta_dict_without_replacement(high_qual_mexican_seqs_for_use,i)\n",
    "        with open(\"../supplemental-analysis/rarefaction-curves/mexico/mexico_{}_seqs/mex_{}_seqs_trial_{}.fasta\".format(i,i,k),'w') as file:\n",
    "            for sequence in subsample:\n",
    "                file.write(str(\">\"+sequence[0] + '\\n' + sequence[1].seq + '\\n'))\n",
    "        \n",
    "    \n",
    "#triall=sample_fasta_dict_without_replacement(high_qual_mexican_seqs_for_use,3)\n",
    "#print(triall[0][1].seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
