{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Dataset curation: making the zika-colombia input fasta dataset\n",
    "  \n",
    "This notebook contains code needed to go from a raw download of all Zika genomes in `nextstrain/fauna` to the input fasta file for the zika-colombia specific analysis (which is done as a custom `nextstrain/augur` build. \n",
    "\n",
    "Here I am removing sequences from geographic areas that I don't want included in this analysis (e.g. Singapore), as well as ensuring that I only keep genomes that I have permission to include in a published analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 694 sequences downloaded from Fauna.\n",
      "Genomes from the following regions will be excluded: southeast_asia, japan_korea, china, and europe.\n",
      "There are 504 sequences meet the geographic criteria.\n"
     ]
    }
   ],
   "source": [
    "# Paths to files, keeping relational show that paths should work if someone downloads the repo as is.\n",
    "fauna_seqs_dict = SeqIO.to_dict(SeqIO.parse('../data/zika-fauna-2018-09-06.fasta', 'fasta'))\n",
    "print 'There are {} sequences downloaded from Fauna.'.format(len(fauna_seqs_dict))\n",
    "\n",
    "#Geographic pruning\n",
    "regions_to_exclude = ['southeast_asia', 'japan_korea', 'china', 'europe', 'africa']\n",
    "print 'Genomes from the following regions will be excluded: {0}, {1}, {2}, and {3}.'.format(regions_to_exclude[0],regions_to_exclude[1],regions_to_exclude[2],regions_to_exclude[3])\n",
    "\n",
    "geoPruned_seqs_dict = {fauna_seqs_dict[key].description:fauna_seqs_dict[key].seq for key in fauna_seqs_dict.keys() if key.split('|')[4] not in regions_to_exclude}\n",
    "print 'There are {} sequences meet the geographic criteria.'.format(len(geoPruned_seqs_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at this point, print out all the genomes are that are left, and ensure that permissions are available.\n",
    "accessions_to_check = [key for key in geoPruned_seqs_dict.keys()]\n",
    "\n",
    "strain_names = [accession.split('|')[0] for accession in accessions_to_check]\n",
    "ncbi_id = [accession.split('|')[2] for accession in accessions_to_check]\n",
    "lead_author =  [accession.split('|')[10].replace('et al','') for accession in accessions_to_check]\n",
    "\n",
    "\n",
    "accessions_df = pd.DataFrame(np.column_stack([strain_names, ncbi_id, lead_author]), columns= ['strain_name', 'accession_number','lead_author'])\n",
    "accessions_df.to_csv('../data/all_included_accessions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 431 genomes that we can include in published analyses.\n"
     ]
    }
   ],
   "source": [
    "# read in the dataframe that has the permissions information,\n",
    "# then parse that to select out all strains that can be included in a publishable analysis\n",
    "# these are the strains that should be used, and form the fauna subset we want.\n",
    "\n",
    "genome_permissions = pd.read_csv('../data/genome-permissions-2018-09-06.txt', delimiter ='\\t')\n",
    "\n",
    "publishable_strains = []\n",
    "for i in range(len(genome_permissions)):\n",
    "    record = genome_permissions.iloc[i]\n",
    "    if record['permission_to_use'] != 'permission_not_received' and record['preliminarily_include'] == 'yes':\n",
    "        publishable_strains.append(record['strain_name'])\n",
    "\n",
    "print \"There are {} genomes that we can include in published analyses.\".format(len(publishable_strains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the strains in the publishable_strains list, pull out the full fauna headers (and sequences)\n",
    "# for each strain that can be published on.\n",
    "# then make a new fauna-formatted fasta file that can be read in to Augur for analysis.\n",
    "\n",
    "publishable_seqs_dict = {}\n",
    "for strain in publishable_strains:\n",
    "    for key in geoPruned_seqs_dict.keys():\n",
    "        if key.startswith(strain):\n",
    "            publishable_seqs_dict[key] = geoPruned_seqs_dict[key]\n",
    "\n",
    "with open('../data/publishable-zika-fauna-2018-09-06.fasta','w') as file:\n",
    "    for key in publishable_seqs_dict.keys():\n",
    "        file.write(str('>' + key + '\\n' + publishable_seqs_dict[key] + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace n's with gaps, and count n's in sequences (alignment checks)\n",
    "\n",
    "def count_n(sequence):\n",
    "    counter = 0\n",
    "    for base in sequence:\n",
    "        if base == 'n':\n",
    "            counter +=1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = SeqIO.to_dict(SeqIO.parse('../data/publishable-zika-fauna-2018-09-06.fasta', 'fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_counts_dict = {}\n",
    "for key in sequences.keys():\n",
    "    n_count = count_n(sequences[key].seq)\n",
    "    n_counts_dict[key] = n_count\n",
    "\n",
    "gaps_not_n_seqs = {}\n",
    "for key in sequences.keys():\n",
    "    n_seq = str(sequences[key].seq)\n",
    "    gap_seq = n_seq.replace('n','-')\n",
    "    gaps_not_n_seqs[key] = gap_seq\n",
    "    \n",
    "high_qual_seqs = {}\n",
    "for key in n_counts_dict.keys():\n",
    "    if key.split('|')[5] == 'colombia':\n",
    "        high_qual_seqs[key] = sequences[key].seq\n",
    "    else:\n",
    "        if float(n_counts_dict[key])/10769 < 0.2:\n",
    "            high_qual_seqs[key] = sequences[key].seq\n",
    "            \n",
    "medium_qual_seqs = {}\n",
    "for key in n_counts_dict.keys():\n",
    "    if key.split('|')[5] == 'colombia':\n",
    "        medium_qual_seqs[key] = sequences[key].seq\n",
    "    else:\n",
    "        if float(n_counts_dict[key])/10769 < 0.5:\n",
    "            medium_qual_seqs[key] = sequences[key].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "415\n"
     ]
    }
   ],
   "source": [
    "print len(high_qual_seqs)\n",
    "with open('../data/publishable-zika-fauna-2018-09-06-high-quality.fasta','w') as file:\n",
    "    for key in high_qual_seqs.keys():\n",
    "        file.write(str('>' + key + '\\n' + high_qual_seqs[key] + '\\n'))\n",
    "        \n",
    "print len(medium_qual_seqs)\n",
    "with open('../data/publishable-zika-fauna-2018-09-06-medium-quality.fasta','w') as file:\n",
    "    for key in medium_qual_seqs.keys():\n",
    "        file.write(str('>' + key + '\\n' + medium_qual_seqs[key] + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/publishable-zika-fauna-2018-09-06-gapped.fasta','w') as file:\n",
    "    for key in gaps_not_n_seqs.keys():\n",
    "        file.write(str('>' + key + '\\n' + gaps_not_n_seqs[key] + '\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
